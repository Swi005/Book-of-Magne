\chapter{Anatomy of an Interpreter}
\label{sec:anatomy}
        
An \gls{interpreter} is a computer program that directly executes instructions written in a programming language.
This differs from a \glspl{compiler} which translates a program from one language to another(usually to a lower level one ex. C or ASM).\\
We usually divide the compiler/interpreter process into two categories, front end, and back end.
The front end is the part of the compiler/interpreter that takes the source code and converts it into some intermediate representation.
In compilers, this is usually some form of byte code or 3-word code, that can then be translated into the target language. 
This is not necessary for an interpreter where the intermediary representation is often in the form of an annotated AST.
The back end is the part of the compiler/interpreter that takes the intermediary representation and executes it(in the case of interpreters) or translates it back into code(compilers).\\

\section{Phases of an interpreter}
An interpreter is composed of several phases. \\
The front end consists of the lexical analyzer, the syntax analyzer, and the semantic analyzer.\\
The backend is the evaluator.\\
The \gls{lexical analysis} takes the actual characters that the code is made up of and divides it up into its lexical tokens(by the tokenizer) using the concrete syntax of the program\footnote{Not covered by this course, so you can safely ignore how this works.... \textit{for now!}}. 
Take for instance the following expression:
\\
\begin{equation*}
    (1+2)*13
\end{equation*}\\
\\
The lexical analyzer would divide this into the following tokens:
\texttt{["(", "1", "+", "2", ")", "*", "13"]}
\newpage
This list of tokens is then sent to the \gls{syntax analyzer}\\
The syntax analyzer takes the token list and builds a parse tree out of the tokens and the concrete syntax (fig.\ref{fig:parsetree}).
\begin{figure}[!h]
    \centering
    \begin{tikzcd}
        \node[] (e0) {"expr"};
        \node[below left = of e0] (e1) {"expr"};
        \node[below left = of e1] (e11) {"("};
        \node[below = of e1] (e12) {"expr"};
        \node[below right = of e1] (e13) {")"};
        \node[below left = of e12] (e121) {"number"};
        \node[below = of e121] (e1211) {"1"};
        \node[below = of e12] (e122) {"+"};
        \node[below right = of e12] (e123) {"number"};
        \node[below = of e123] (e1231) {"2"};
        \node[below = of e0] (e2) {"*"};
        \node[below right = of e0] (e3) {"number"};
        \node[below = of e3] (e31) {"13"};

        \draw (e0) edge (e1)
            (e0) edge (e2)
            (e0) edge (e3)
            (e1) edge (e11)
            (e1) edge (e12)
            (e1) edge (e13)
            (e12) edge (e121)
            (e12) edge (e122)
            (e12) edge (e123)
            (e121) edge (e1211)
            (e123) edge (e1231);

    \end{tikzcd}
    \caption{Parse tree}
    \label{fig:parsetree}
\end{figure}

The parse tree is then converted into an \gls{AST} by the abstract syntax rules (fig.\ref{fig:ast}).

\begin{figure}[!h]
    \centering
    \begin{tikzcd}
        \node[] (e0) {\texttt{Mult}};
        \node[below left = of e0] (e1) {\texttt{Add}};
        \node[below left = of e1] (e11) {\texttt{1}};
        \node[below right = of e1] (e12) {\texttt{2}};
        \node[below right = of e0] (e2) {\texttt{13}};

        \draw (e0) edge (e1)
            (e0) edge (e2)
            (e1) edge (e11)
            (e1) edge (e12);
    \end{tikzcd}
    \label{fig:ast}
    \caption{AST}
\end{figure}

The syntax analyzer builds a parse tree out of the tokens and the concrete syntax. 
This is then converted into an AST by the abstract syntax rules. 
Which is then handed over to the next part, the \gls{semantic analyzer}.
The AST is type-checked, checked for well-formedness, names are resolved, and types are inferred. The new AST, now with added information, is then given to the evaluator so that it can be evaluated and produce a result.
See Fig. \ref{fig:interpreterphases}.

\begin{figure}[ht]
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \fbox{\centering
        \begin{tikzcd}
            \parbox{\textwidth}{}\arrow[d, "\text{character stream}"]\\
            \fbox{\parbox{10em}{\centering Lexical Analyzer}}\arrow[d, "\text{token stream}"]\\
            \fbox{\parbox{10em}{\centering Syntax Analyzer}}\arrow[d, "\text{syntax tree(AST)}"]\\
            \fbox{\parbox{10em}{\centering Semantic Analyzer}}\arrow[d,"\text{syntax tree(Annotated AST)}"]\\
            \fbox{\parbox{10em}{\centering Evaluator}}\arrow[d, "\text{result}"]\\
            \parbox{\textwidth}{}
        \end{tikzcd}}
        \caption{Phases of an interpreter}
        \label{fig:interpreterphases}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \fbox{\centering
        \begin{tikzcd}
            \parbox{\textwidth}{}\arrow[d, "\text{character stream}"]\\
            \fbox{\parbox{10em}{\centering Lexical Analyzer}}\arrow[d, "\text{token stream}"]\\
            \fbox{\parbox{10em}{\centering Syntax Analyzer}}\arrow[d, "\text{syntax tree(AST)}"]\\
            \fbox{\parbox{10em}{\centering Semantic Analyzer}}\arrow[d,"\text{syntax tree(Annotated AST)}"]\\
            \fbox{\parbox{10em}{\centering Intermediate Code Generator}}\arrow[d, "\text{Intermediate representation}"]\\
            \fbox{\parbox{10em}{\centering Machine-Independent Code Optimization}}\arrow[d, "\text{Intermediate representation}"]\\
            \fbox{\parbox{10em}{\centering Code Generator}}\arrow[d, "\text{target machine code}"]\\
            \fbox{\parbox{10em}{\centering Machine-Dependent Code Optimization}}\arrow[d, "\text{target-machine code}"]\\
            \parbox{\textwidth}{}
        \end{tikzcd}}
        \caption{Phases of a "normal" compiler}
        \label{fig:compilerphases}
    \end{minipage}%
    \caption{Please appreciate the figures above, they were hard to make}
\end{figure}%
\newpage
    \section{ASTs}
        An \gls{AST} is the tree representation of the syntactic structure of a program; The abstract syntax
        describes the structure of the abstract syntax tree - it can be defined using a
        regular tree grammar, or an algebraic data type or term (in Rascal, ML, Prolog,
        ...), or an object-oriented inheritance hierarchy of node classes (Java, C++, ...),
        or as an S-expression (in Lisp languages).
        The abstract syntax tree can be used as an internal representation in a language processor, 
        but it is not the only possible representation.\\
        An abstract syntax can be generated by a grammar in the following way:
        For every non-terminal type, there is a corresponding abstract syntax type.
        Each type has one constructor (or node type) corresponding to each production in the grammar, with one child for every symbol in the production that
        is not a literal token (e.g., punctuation, keywords, or spaces). If a constructor
        has only one child, of the same type, it can be removed (e.g., this would be
        the case for a parenthesis expression). You can do this process entirely based
        on the information contained in a parse tree. Translating a parse tree into a
        corresponding abstract syntax tree is called imploding the parse tree.
        Given an abstract syntax tree, it is possible to reconstruct a parse tree or program text, given the original grammar - though the resulting program may be
        slightly different in terms of spaces and punctuation. 
        This is called unparsing or pretty-printing (particularly if the output is nicely formatted). Parsing, imploding, pretty-printing, and then reparsing may not yield the exact same parse tree
        as the original tree, but it should still implode to the same abstract syntax tree (otherwise there is a bug in your toolchain!).

        Various phases in a language processor may change the abstract syntax
        tree, or use slightly different versions of the abstract syntax (e.g., after type
        checking, the nodes for variables include the type of the variable) - it is also
        possible to decorate or annotate the AST as processing proceeds. 
        This adds extra information to the nodes in the AST, without impacting the structure of the abstract syntax.
        Important abstract syntax design considerations are;
        \begin{itemize}
            \item Simplicity. Generally, your compiler tools will do a lot of work on AST,
            and the fewer different cases you have to worry about, the better. For
            For example, if the processing of overloaded functions and operators is the same (which it is to some degree in C++), you may want to have
            only one AST node type to cover both. Having a lot of unnecessary nodes
            in the tree can be annoying as well, and may make processing slower.
            \item Good correspondence with the constructs of the language.
            \item Availability of information during processing. Some information 
            can be computed from the tree (such as type information) and might be encoded directly in the tree (at least at later stages) for easy processing.
            \item Being end-user friendly or familiar to most programmers isn't an important consideration - the abstract syntax may be radically different from
            the surface concrete syntax if that helps the compiler writer.
        \end{itemize}

    \section{Static Analysis}
        \subsection{Type Checking}
        Programming language typing always falls into one or two categories; static, and dynamic typing. Static typing is when type checking happens at compile-time, 
        while dynamic typing happens during runtime. We will focus on static typing. 
        Statically typed languages typically have these properties.
        \begin{itemize}
            \item Variables and data structures must be declared before use.
            \item Variables and data structure fields can only hold values of the declared type.
            \item Operations(i.e functions, procedures, methods) and types must be declared.
            \item Declaring the exact types of variables and operations isn't always needed. Some languages use type inference (Discussed in 3.2.3).
        \end{itemize}

        What is a type checker and how does it work? 
        A type checker is a meta-program that checks that verifies that the type of some construct(lists, expressions, etc.) matches what's expected of it.
        For example, a type checker will check that the Plus \gls{expression} takes two Integers. 
        \newpage
        This lets the type checker discover and report certain errors before the program runs. 
        To do this a type checker needs to know;
        \begin{itemize}
            \item How the language should look.
            \item The language types.
            \item Rules for assigning types to the constructs.
        \end{itemize}
        \subsubsection*{Let's do a practical example}
        Here's the abstract syntax for our Simple Typed Language or STL for short.
        \lstinputlisting[language=Haskell, firstline=2, lastline=11]{figures/code/typecheck/typecheck.hs}
        Before we can continue we need to define the types that are allowed. We decide to use two types, Integers, and Booleans.
        \lstinputlisting[language=Haskell, firstline=12, lastline=12]{figures/code/typecheck/typecheck.hs}
        
        Now to the meat of the exercise, the type checker itself.
        The usual way to do this in Haskell(and most other languages I've experienced) is to define a series of recursive functions, one for each
        expression/operand.
        \lstinputlisting[language=Haskell, firstline=14, lastline=14]{figures/code/typecheck/typecheck.hs}
        
        I have found it easiest, to begin with, the cases that form the basic "building blocks" of a language, the literals. It is easy to know the type of Int Literals(Integer obviously), and Bool Literals(Boolean).
        \lstinputlisting[language=Haskell, firstline=15, lastline=16]{figures/code/typecheck/typecheck.hs}
        
        After these "base" cases we add a case for Vars, this is slightly more complicated since the type is dependent on the list of var declarations, 
        so we need to check the VarDecl list.
        \lstinputlisting[language=Haskell, firstline=18, lastline=21]{figures/code/typecheck/typecheck.hs}
        
        We use a pretty clever Haskell expression called "case". This lets us pattern match the result of the function call in lookup. 
        I strongly recommend that you all learn how to use these since they are extremely useful and I'll be using them liberally during this example.\\
        We now move on to the ops.
        \lstinputlisting[language=Haskell, firstline=23, lastline=48]{figures/code/typecheck/typecheck.hs}
        
        These all more-or-less follow the same pattern \footnote{Maya made me use fancier words, apparently "pretty similar" isn't good enough.}.
        They all check that the arguments are of the correct type and return the operand type if so, if not they raise an error.
        Eq is the odd one out since it returns a boolean no matter what since it checks if two expressions are the same.\\
        The last case is the most complex. Choice tests a boolean condition and returns one of the two expressions depending on the value.
        The problem is that we don't know which branch will return. We have therefore decided both branches need to be of the same type.
        \lstinputlisting[language=Haskell, firstline=50, lastline=57]{figures/code/typecheck/typecheck.hs}
           
        Here we begin by checking that the test evals to a boolean type, if so we check that both branches have the same type and return that type.
        Note that even though an evaluator would only evaluate one of the two branches, we still type-check them both.
        
        
        \subsection{Wellformedness}
            For a program to be \gls{wellformed} it needs to satisfy all the constraints(think rules) on it. This means that the program follows all the rules 
            for it like; 
            \begin{itemize}
                \item The program conforms to the AST.
                \item It is typed correctly
                \item All procedure calls/declarations are wellformed.
                \item and much more.
            \end{itemize}

            To check if a program is wellformed we usually implement a so-called constraint checker. These are pretty much just unit tests.
            The recipe for a constrain checker is as follows;
            \begin{itemize}
                \item \textbf{Negative test cases} - Designate one negative test case for each constraint that should be checked. 
                Ideally, each such test case should violate only one constraint.
                \item \textbf{Reporting} - Choose an approach to "reporting". The result of constraint violation may be communicated either through
                                        a boolean value, as a list of errors, or by throwing an exception.
                \item \textbf{Modularity} - Implement each constraint in a separate function, thereby allowing modularity and testing.
                \item \textbf{Testing} - The constraint violations must be correctly detected for the negative test cases. The positive test case must pass.
            \end{itemize}

    